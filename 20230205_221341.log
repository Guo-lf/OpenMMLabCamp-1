2023-02-05 22:13:44,407 - mmcls - INFO - Environment info:
------------------------------------------------------------
sys.platform: win32
Python: 3.7.13 (default, Oct 19 2022, 10:19:43) [MSC v.1916 64 bit (AMD64)]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3060
CUDA_HOME: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1
NVCC: Cuda compilation tools, release 11.1, V11.1.74
MSVC: 用于 x64 的 Microsoft (R) C/C++ 优化编译器 19.29.30147 版
GCC: n/a
PyTorch: 1.10.1
PyTorch compiling details: PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, 

TorchVision: 0.11.2
OpenCV: 4.6.0
MMCV: 1.6.2
MMCV Compiler: MSVC 192829924
MMCV CUDA Compiler: 11.3
MMClassification: 0.23.2+
------------------------------------------------------------

2023-02-05 22:13:44,407 - mmcls - INFO - Distributed training: False
2023-02-05 22:13:44,450 - mmcls - INFO - Config:
model = dict(
    type='ImageClassifier',
    backbone=dict(
        type='ResNet_CIFAR',
        depth=34,
        num_stages=4,
        out_indices=(3, ),
        style='pytorch'),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='LinearClsHead',
        num_classes=10,
        in_channels=512,
        loss=dict(type='CrossEntropyLoss', loss_weight=1.0)))
dataset_type = 'CIFAR10'
img_norm_cfg = dict(
    mean=[125.307, 122.961, 113.8575],
    std=[51.5865, 50.847, 51.255],
    to_rgb=False)
train_pipeline = [
    dict(type='RandomCrop', size=32, padding=4),
    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
    dict(
        type='Normalize',
        mean=[125.307, 122.961, 113.8575],
        std=[51.5865, 50.847, 51.255],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='ToTensor', keys=['gt_label']),
    dict(type='Collect', keys=['img', 'gt_label'])
]
test_pipeline = [
    dict(
        type='Normalize',
        mean=[125.307, 122.961, 113.8575],
        std=[51.5865, 50.847, 51.255],
        to_rgb=False),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='Collect', keys=['img'])
]
data = dict(
    samples_per_gpu=32,
    workers_per_gpu=2,
    train=dict(
        type='CIFAR10',
        data_prefix='data/cifar10',
        pipeline=[
            dict(type='RandomCrop', size=32, padding=4),
            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
            dict(
                type='Normalize',
                mean=[125.307, 122.961, 113.8575],
                std=[51.5865, 50.847, 51.255],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['gt_label']),
            dict(type='Collect', keys=['img', 'gt_label'])
        ]),
    val=dict(
        type='CIFAR10',
        data_prefix='data/cifar10',
        pipeline=[
            dict(
                type='Normalize',
                mean=[125.307, 122.961, 113.8575],
                std=[51.5865, 50.847, 51.255],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True),
    test=dict(
        type='CIFAR10',
        data_prefix='data/cifar10',
        pipeline=[
            dict(
                type='Normalize',
                mean=[125.307, 122.961, 113.8575],
                std=[51.5865, 50.847, 51.255],
                to_rgb=False),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ],
        test_mode=True))
optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[100, 150])
runner = dict(type='EpochBasedRunner', max_epochs=200)
checkpoint_config = dict(interval=1)
log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = '../checkpoints/resnet18_b16x8_cifar10_20210528-bd6371c8.pth'
resume_from = None
workflow = [('train', 1)]
work_dir = './work_dirs/resnet34_1xb32_cifar10'
gpu_ids = [0]

2023-02-05 22:13:44,451 - mmcls - INFO - Set random seed to 2045840895, deterministic: False
2023-02-05 22:13:44,523 - mmcls - INFO - initialize ResNet_CIFAR with init_cfg [{'type': 'Kaiming', 'layer': ['Conv2d']}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2023-02-05 22:13:44,605 - mmcls - INFO - initialize LinearClsHead with init_cfg {'type': 'Normal', 'layer': 'Linear', 'std': 0.01}
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.conv1.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.conv1.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv1.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.downsample.0.weight - torch.Size([128, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.downsample.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.downsample.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv1.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.conv1.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.conv1.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet_CIFAR  

backbone.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

head.fc.weight - torch.Size([10, 512]): 
NormalInit: mean=0, std=0.01, bias=0 

head.fc.bias - torch.Size([10]): 
NormalInit: mean=0, std=0.01, bias=0 
2023-02-05 22:13:45,496 - mmcls - INFO - load checkpoint from local path: ../checkpoints/resnet18_b16x8_cifar10_20210528-bd6371c8.pth
2023-02-05 22:13:45,524 - mmcls - WARNING - The model and loaded state dict do not match exactly

missing keys in source state_dict: backbone.layer1.2.conv1.weight, backbone.layer1.2.bn1.weight, backbone.layer1.2.bn1.bias, backbone.layer1.2.bn1.running_mean, backbone.layer1.2.bn1.running_var, backbone.layer1.2.conv2.weight, backbone.layer1.2.bn2.weight, backbone.layer1.2.bn2.bias, backbone.layer1.2.bn2.running_mean, backbone.layer1.2.bn2.running_var, backbone.layer2.2.conv1.weight, backbone.layer2.2.bn1.weight, backbone.layer2.2.bn1.bias, backbone.layer2.2.bn1.running_mean, backbone.layer2.2.bn1.running_var, backbone.layer2.2.conv2.weight, backbone.layer2.2.bn2.weight, backbone.layer2.2.bn2.bias, backbone.layer2.2.bn2.running_mean, backbone.layer2.2.bn2.running_var, backbone.layer2.3.conv1.weight, backbone.layer2.3.bn1.weight, backbone.layer2.3.bn1.bias, backbone.layer2.3.bn1.running_mean, backbone.layer2.3.bn1.running_var, backbone.layer2.3.conv2.weight, backbone.layer2.3.bn2.weight, backbone.layer2.3.bn2.bias, backbone.layer2.3.bn2.running_mean, backbone.layer2.3.bn2.running_var, backbone.layer3.2.conv1.weight, backbone.layer3.2.bn1.weight, backbone.layer3.2.bn1.bias, backbone.layer3.2.bn1.running_mean, backbone.layer3.2.bn1.running_var, backbone.layer3.2.conv2.weight, backbone.layer3.2.bn2.weight, backbone.layer3.2.bn2.bias, backbone.layer3.2.bn2.running_mean, backbone.layer3.2.bn2.running_var, backbone.layer3.3.conv1.weight, backbone.layer3.3.bn1.weight, backbone.layer3.3.bn1.bias, backbone.layer3.3.bn1.running_mean, backbone.layer3.3.bn1.running_var, backbone.layer3.3.conv2.weight, backbone.layer3.3.bn2.weight, backbone.layer3.3.bn2.bias, backbone.layer3.3.bn2.running_mean, backbone.layer3.3.bn2.running_var, backbone.layer3.4.conv1.weight, backbone.layer3.4.bn1.weight, backbone.layer3.4.bn1.bias, backbone.layer3.4.bn1.running_mean, backbone.layer3.4.bn1.running_var, backbone.layer3.4.conv2.weight, backbone.layer3.4.bn2.weight, backbone.layer3.4.bn2.bias, backbone.layer3.4.bn2.running_mean, backbone.layer3.4.bn2.running_var, backbone.layer3.5.conv1.weight, backbone.layer3.5.bn1.weight, backbone.layer3.5.bn1.bias, backbone.layer3.5.bn1.running_mean, backbone.layer3.5.bn1.running_var, backbone.layer3.5.conv2.weight, backbone.layer3.5.bn2.weight, backbone.layer3.5.bn2.bias, backbone.layer3.5.bn2.running_mean, backbone.layer3.5.bn2.running_var, backbone.layer4.2.conv1.weight, backbone.layer4.2.bn1.weight, backbone.layer4.2.bn1.bias, backbone.layer4.2.bn1.running_mean, backbone.layer4.2.bn1.running_var, backbone.layer4.2.conv2.weight, backbone.layer4.2.bn2.weight, backbone.layer4.2.bn2.bias, backbone.layer4.2.bn2.running_mean, backbone.layer4.2.bn2.running_var

2023-02-05 22:13:45,527 - mmcls - INFO - Start running, host: a@DESKTOP-GBB9C9S, work_dir: E:\2023\mmlab\mmclassification-master\mmclassification-master\tools\work_dirs\resnet34_1xb32_cifar10
2023-02-05 22:13:45,527 - mmcls - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-05 22:13:45,527 - mmcls - INFO - workflow: [('train', 1)], max: 200 epochs
2023-02-05 22:13:45,527 - mmcls - INFO - Checkpoints will be saved to E:\2023\mmlab\mmclassification-master\mmclassification-master\tools\work_dirs\resnet34_1xb32_cifar10 by HardDiskBackend.
2023-02-05 22:14:03,503 - mmcls - INFO - Epoch [1][100/1563]	lr: 1.000e-03, eta: 15:34:04, time: 0.179, data_time: 0.080, memory: 576, loss: 0.0007
2023-02-05 22:14:09,579 - mmcls - INFO - Epoch [1][200/1563]	lr: 1.000e-03, eta: 10:25:05, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:14:15,699 - mmcls - INFO - Epoch [1][300/1563]	lr: 1.000e-03, eta: 8:42:46, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:14:21,786 - mmcls - INFO - Epoch [1][400/1563]	lr: 1.000e-03, eta: 7:51:07, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:14:27,870 - mmcls - INFO - Epoch [1][500/1563]	lr: 1.000e-03, eta: 7:20:03, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:14:33,953 - mmcls - INFO - Epoch [1][600/1563]	lr: 1.000e-03, eta: 6:59:19, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0009
2023-02-05 22:14:40,043 - mmcls - INFO - Epoch [1][700/1563]	lr: 1.000e-03, eta: 6:44:31, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0013
2023-02-05 22:14:46,134 - mmcls - INFO - Epoch [1][800/1563]	lr: 1.000e-03, eta: 6:33:25, time: 0.061, data_time: 0.000, memory: 576, loss: 0.0009
2023-02-05 22:14:52,210 - mmcls - INFO - Epoch [1][900/1563]	lr: 1.000e-03, eta: 6:24:39, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:14:58,252 - mmcls - INFO - Epoch [1][1000/1563]	lr: 1.000e-03, eta: 6:17:27, time: 0.060, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:15:04,295 - mmcls - INFO - Epoch [1][1100/1563]	lr: 1.000e-03, eta: 6:11:33, time: 0.060, data_time: 0.001, memory: 576, loss: 0.0011
2023-02-05 22:15:10,347 - mmcls - INFO - Epoch [1][1200/1563]	lr: 1.000e-03, eta: 6:06:39, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0013
2023-02-05 22:15:16,400 - mmcls - INFO - Epoch [1][1300/1563]	lr: 1.000e-03, eta: 6:02:30, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0009
2023-02-05 22:15:22,443 - mmcls - INFO - Epoch [1][1400/1563]	lr: 1.000e-03, eta: 5:58:53, time: 0.060, data_time: 0.001, memory: 576, loss: 0.0010
2023-02-05 22:15:28,487 - mmcls - INFO - Epoch [1][1500/1563]	lr: 1.000e-03, eta: 5:55:45, time: 0.060, data_time: 0.001, memory: 576, loss: 0.0010
2023-02-05 22:15:32,255 - mmcls - INFO - Saving checkpoint at 1 epochs
2023-02-05 22:15:42,332 - mmcls - INFO - Epoch(val) [1][313]	accuracy_top-1: 94.8700, accuracy_top-5: 99.8500
2023-02-05 22:15:50,533 - mmcls - INFO - Epoch [2][100/1563]	lr: 1.000e-03, eta: 5:46:07, time: 0.082, data_time: 0.020, memory: 576, loss: 0.0006
2023-02-05 22:15:56,582 - mmcls - INFO - Epoch [2][200/1563]	lr: 1.000e-03, eta: 5:44:09, time: 0.060, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:16:02,640 - mmcls - INFO - Epoch [2][300/1563]	lr: 1.000e-03, eta: 5:42:25, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:16:08,776 - mmcls - INFO - Epoch [2][400/1563]	lr: 1.000e-03, eta: 5:41:04, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0010
2023-02-05 22:16:14,934 - mmcls - INFO - Epoch [2][500/1563]	lr: 1.000e-03, eta: 5:39:53, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0010
2023-02-05 22:16:21,071 - mmcls - INFO - Epoch [2][600/1563]	lr: 1.000e-03, eta: 5:38:43, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0010
2023-02-05 22:16:27,136 - mmcls - INFO - Epoch [2][700/1563]	lr: 1.000e-03, eta: 5:37:31, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:16:33,201 - mmcls - INFO - Epoch [2][800/1563]	lr: 1.000e-03, eta: 5:36:23, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0009
2023-02-05 22:16:39,275 - mmcls - INFO - Epoch [2][900/1563]	lr: 1.000e-03, eta: 5:35:22, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:16:45,348 - mmcls - INFO - Epoch [2][1000/1563]	lr: 1.000e-03, eta: 5:34:26, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:16:51,428 - mmcls - INFO - Epoch [2][1100/1563]	lr: 1.000e-03, eta: 5:33:34, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:16:57,495 - mmcls - INFO - Epoch [2][1200/1563]	lr: 1.000e-03, eta: 5:32:43, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:17:03,572 - mmcls - INFO - Epoch [2][1300/1563]	lr: 1.000e-03, eta: 5:31:57, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:17:09,642 - mmcls - INFO - Epoch [2][1400/1563]	lr: 1.000e-03, eta: 5:31:13, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0009
2023-02-05 22:17:15,708 - mmcls - INFO - Epoch [2][1500/1563]	lr: 1.000e-03, eta: 5:30:31, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0015
2023-02-05 22:17:19,491 - mmcls - INFO - Saving checkpoint at 2 epochs
2023-02-05 22:17:25,559 - mmcls - INFO - Epoch(val) [2][313]	accuracy_top-1: 94.9600, accuracy_top-5: 99.8500
2023-02-05 22:17:33,834 - mmcls - INFO - Epoch [3][100/1563]	lr: 1.000e-03, eta: 5:26:49, time: 0.082, data_time: 0.020, memory: 576, loss: 0.0013
2023-02-05 22:17:39,906 - mmcls - INFO - Epoch [3][200/1563]	lr: 1.000e-03, eta: 5:26:18, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0009
2023-02-05 22:17:45,984 - mmcls - INFO - Epoch [3][300/1563]	lr: 1.000e-03, eta: 5:25:48, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:17:52,073 - mmcls - INFO - Epoch [3][400/1563]	lr: 1.000e-03, eta: 5:25:22, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0010
2023-02-05 22:17:58,158 - mmcls - INFO - Epoch [3][500/1563]	lr: 1.000e-03, eta: 5:24:56, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:18:04,239 - mmcls - INFO - Epoch [3][600/1563]	lr: 1.000e-03, eta: 5:24:30, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:18:10,312 - mmcls - INFO - Epoch [3][700/1563]	lr: 1.000e-03, eta: 5:24:05, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:18:16,388 - mmcls - INFO - Epoch [3][800/1563]	lr: 1.000e-03, eta: 5:23:41, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:18:22,457 - mmcls - INFO - Epoch [3][900/1563]	lr: 1.000e-03, eta: 5:23:18, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:18:28,534 - mmcls - INFO - Epoch [3][1000/1563]	lr: 1.000e-03, eta: 5:22:56, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0011
2023-02-05 22:18:34,606 - mmcls - INFO - Epoch [3][1100/1563]	lr: 1.000e-03, eta: 5:22:35, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:18:40,684 - mmcls - INFO - Epoch [3][1200/1563]	lr: 1.000e-03, eta: 5:22:14, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:18:46,756 - mmcls - INFO - Epoch [3][1300/1563]	lr: 1.000e-03, eta: 5:21:54, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:18:52,835 - mmcls - INFO - Epoch [3][1400/1563]	lr: 1.000e-03, eta: 5:21:35, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:18:58,911 - mmcls - INFO - Epoch [3][1500/1563]	lr: 1.000e-03, eta: 5:21:16, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:19:02,703 - mmcls - INFO - Saving checkpoint at 3 epochs
2023-02-05 22:19:08,810 - mmcls - INFO - Epoch(val) [3][313]	accuracy_top-1: 94.8700, accuracy_top-5: 99.8500
2023-02-05 22:19:17,070 - mmcls - INFO - Epoch [4][100/1563]	lr: 1.000e-03, eta: 5:18:58, time: 0.082, data_time: 0.020, memory: 576, loss: 0.0007
2023-02-05 22:19:23,165 - mmcls - INFO - Epoch [4][200/1563]	lr: 1.000e-03, eta: 5:18:44, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:19:29,321 - mmcls - INFO - Epoch [4][300/1563]	lr: 1.000e-03, eta: 5:18:35, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0005
2023-02-05 22:19:35,499 - mmcls - INFO - Epoch [4][400/1563]	lr: 1.000e-03, eta: 5:18:27, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:19:41,677 - mmcls - INFO - Epoch [4][500/1563]	lr: 1.000e-03, eta: 5:18:18, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0011
2023-02-05 22:19:47,849 - mmcls - INFO - Epoch [4][600/1563]	lr: 1.000e-03, eta: 5:18:10, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:19:54,023 - mmcls - INFO - Epoch [4][700/1563]	lr: 1.000e-03, eta: 5:18:01, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:20:00,194 - mmcls - INFO - Epoch [4][800/1563]	lr: 1.000e-03, eta: 5:17:53, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:20:06,368 - mmcls - INFO - Epoch [4][900/1563]	lr: 1.000e-03, eta: 5:17:45, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0014
2023-02-05 22:20:12,541 - mmcls - INFO - Epoch [4][1000/1563]	lr: 1.000e-03, eta: 5:17:36, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0006
2023-02-05 22:20:18,713 - mmcls - INFO - Epoch [4][1100/1563]	lr: 1.000e-03, eta: 5:17:28, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:20:24,882 - mmcls - INFO - Epoch [4][1200/1563]	lr: 1.000e-03, eta: 5:17:20, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0021
2023-02-05 22:20:31,057 - mmcls - INFO - Epoch [4][1300/1563]	lr: 1.000e-03, eta: 5:17:12, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0009
2023-02-05 22:20:37,230 - mmcls - INFO - Epoch [4][1400/1563]	lr: 1.000e-03, eta: 5:17:04, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:20:43,401 - mmcls - INFO - Epoch [4][1500/1563]	lr: 1.000e-03, eta: 5:16:56, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0006
2023-02-05 22:20:47,249 - mmcls - INFO - Saving checkpoint at 4 epochs
2023-02-05 22:20:53,854 - mmcls - INFO - Epoch(val) [4][313]	accuracy_top-1: 94.8800, accuracy_top-5: 99.8700
2023-02-05 22:21:02,262 - mmcls - INFO - Epoch [5][100/1563]	lr: 1.000e-03, eta: 5:15:22, time: 0.084, data_time: 0.020, memory: 576, loss: 0.0008
2023-02-05 22:21:08,436 - mmcls - INFO - Epoch [5][200/1563]	lr: 1.000e-03, eta: 5:15:16, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0011
2023-02-05 22:21:14,608 - mmcls - INFO - Epoch [5][300/1563]	lr: 1.000e-03, eta: 5:15:09, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:21:20,780 - mmcls - INFO - Epoch [5][400/1563]	lr: 1.000e-03, eta: 5:15:03, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0015
2023-02-05 22:21:26,949 - mmcls - INFO - Epoch [5][500/1563]	lr: 1.000e-03, eta: 5:14:56, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0006
2023-02-05 22:21:33,118 - mmcls - INFO - Epoch [5][600/1563]	lr: 1.000e-03, eta: 5:14:49, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:21:39,290 - mmcls - INFO - Epoch [5][700/1563]	lr: 1.000e-03, eta: 5:14:43, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:21:45,462 - mmcls - INFO - Epoch [5][800/1563]	lr: 1.000e-03, eta: 5:14:36, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:21:51,634 - mmcls - INFO - Epoch [5][900/1563]	lr: 1.000e-03, eta: 5:14:30, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0012
2023-02-05 22:21:57,807 - mmcls - INFO - Epoch [5][1000/1563]	lr: 1.000e-03, eta: 5:14:23, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0008
2023-02-05 22:22:03,980 - mmcls - INFO - Epoch [5][1100/1563]	lr: 1.000e-03, eta: 5:14:17, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:22:10,153 - mmcls - INFO - Epoch [5][1200/1563]	lr: 1.000e-03, eta: 5:14:11, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0008
2023-02-05 22:22:16,329 - mmcls - INFO - Epoch [5][1300/1563]	lr: 1.000e-03, eta: 5:14:04, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:22:22,502 - mmcls - INFO - Epoch [5][1400/1563]	lr: 1.000e-03, eta: 5:13:58, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0007
2023-02-05 22:22:28,681 - mmcls - INFO - Epoch [5][1500/1563]	lr: 1.000e-03, eta: 5:13:52, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0006
2023-02-05 22:22:32,538 - mmcls - INFO - Saving checkpoint at 5 epochs
2023-02-05 22:22:39,121 - mmcls - INFO - Epoch(val) [5][313]	accuracy_top-1: 94.8300, accuracy_top-5: 99.8400
2023-02-05 22:22:47,498 - mmcls - INFO - Epoch [6][100/1563]	lr: 1.000e-03, eta: 5:12:35, time: 0.083, data_time: 0.020, memory: 576, loss: 0.0009
2023-02-05 22:22:53,674 - mmcls - INFO - Epoch [6][200/1563]	lr: 1.000e-03, eta: 5:12:30, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:22:59,848 - mmcls - INFO - Epoch [6][300/1563]	lr: 1.000e-03, eta: 5:12:24, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0005
2023-02-05 22:23:06,019 - mmcls - INFO - Epoch [6][400/1563]	lr: 1.000e-03, eta: 5:12:19, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0007
2023-02-05 22:23:12,190 - mmcls - INFO - Epoch [6][500/1563]	lr: 1.000e-03, eta: 5:12:13, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:23:18,364 - mmcls - INFO - Epoch [6][600/1563]	lr: 1.000e-03, eta: 5:12:08, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0005
2023-02-05 22:23:24,537 - mmcls - INFO - Epoch [6][700/1563]	lr: 1.000e-03, eta: 5:12:02, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0006
2023-02-05 22:23:30,711 - mmcls - INFO - Epoch [6][800/1563]	lr: 1.000e-03, eta: 5:11:56, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0006
2023-02-05 22:23:36,887 - mmcls - INFO - Epoch [6][900/1563]	lr: 1.000e-03, eta: 5:11:51, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:23:43,061 - mmcls - INFO - Epoch [6][1000/1563]	lr: 1.000e-03, eta: 5:11:45, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0009
2023-02-05 22:23:49,237 - mmcls - INFO - Epoch [6][1100/1563]	lr: 1.000e-03, eta: 5:11:39, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0007
2023-02-05 22:23:55,410 - mmcls - INFO - Epoch [6][1200/1563]	lr: 1.000e-03, eta: 5:11:34, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0008
2023-02-05 22:24:01,590 - mmcls - INFO - Epoch [6][1300/1563]	lr: 1.000e-03, eta: 5:11:28, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:24:07,761 - mmcls - INFO - Epoch [6][1400/1563]	lr: 1.000e-03, eta: 5:11:22, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0007
2023-02-05 22:24:13,853 - mmcls - INFO - Epoch [6][1500/1563]	lr: 1.000e-03, eta: 5:11:14, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0011
2023-02-05 22:24:17,720 - mmcls - INFO - Saving checkpoint at 6 epochs
2023-02-05 22:24:24,419 - mmcls - INFO - Epoch(val) [6][313]	accuracy_top-1: 94.9600, accuracy_top-5: 99.8600
2023-02-05 22:24:32,822 - mmcls - INFO - Epoch [7][100/1563]	lr: 1.000e-03, eta: 5:10:11, time: 0.084, data_time: 0.020, memory: 576, loss: 0.0005
2023-02-05 22:24:39,001 - mmcls - INFO - Epoch [7][200/1563]	lr: 1.000e-03, eta: 5:10:06, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:24:45,178 - mmcls - INFO - Epoch [7][300/1563]	lr: 1.000e-03, eta: 5:10:01, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:24:51,361 - mmcls - INFO - Epoch [7][400/1563]	lr: 1.000e-03, eta: 5:09:56, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0007
2023-02-05 22:24:57,559 - mmcls - INFO - Epoch [7][500/1563]	lr: 1.000e-03, eta: 5:09:52, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0006
2023-02-05 22:25:03,769 - mmcls - INFO - Epoch [7][600/1563]	lr: 1.000e-03, eta: 5:09:48, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0010
2023-02-05 22:25:09,960 - mmcls - INFO - Epoch [7][700/1563]	lr: 1.000e-03, eta: 5:09:43, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0008
2023-02-05 22:25:16,163 - mmcls - INFO - Epoch [7][800/1563]	lr: 1.000e-03, eta: 5:09:39, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:25:22,363 - mmcls - INFO - Epoch [7][900/1563]	lr: 1.000e-03, eta: 5:09:34, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0013
2023-02-05 22:25:28,552 - mmcls - INFO - Epoch [7][1000/1563]	lr: 1.000e-03, eta: 5:09:29, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0004
2023-02-05 22:25:34,674 - mmcls - INFO - Epoch [7][1100/1563]	lr: 1.000e-03, eta: 5:09:22, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0010
2023-02-05 22:25:40,818 - mmcls - INFO - Epoch [7][1200/1563]	lr: 1.000e-03, eta: 5:09:16, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0005
2023-02-05 22:25:47,011 - mmcls - INFO - Epoch [7][1300/1563]	lr: 1.000e-03, eta: 5:09:12, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0007
2023-02-05 22:25:53,203 - mmcls - INFO - Epoch [7][1400/1563]	lr: 1.000e-03, eta: 5:09:07, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:25:59,400 - mmcls - INFO - Epoch [7][1500/1563]	lr: 1.000e-03, eta: 5:09:02, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0011
2023-02-05 22:26:03,266 - mmcls - INFO - Saving checkpoint at 7 epochs
2023-02-05 22:26:10,538 - mmcls - INFO - Epoch(val) [7][313]	accuracy_top-1: 94.9500, accuracy_top-5: 99.8300
2023-02-05 22:26:18,979 - mmcls - INFO - Epoch [8][100/1563]	lr: 1.000e-03, eta: 5:08:08, time: 0.084, data_time: 0.020, memory: 576, loss: 0.0008
2023-02-05 22:26:25,183 - mmcls - INFO - Epoch [8][200/1563]	lr: 1.000e-03, eta: 5:08:04, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0010
2023-02-05 22:26:31,382 - mmcls - INFO - Epoch [8][300/1563]	lr: 1.000e-03, eta: 5:07:59, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0005
2023-02-05 22:26:37,580 - mmcls - INFO - Epoch [8][400/1563]	lr: 1.000e-03, eta: 5:07:55, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0005
2023-02-05 22:26:43,780 - mmcls - INFO - Epoch [8][500/1563]	lr: 1.000e-03, eta: 5:07:51, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0015
2023-02-05 22:26:49,985 - mmcls - INFO - Epoch [8][600/1563]	lr: 1.000e-03, eta: 5:07:46, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0006
2023-02-05 22:26:56,116 - mmcls - INFO - Epoch [8][700/1563]	lr: 1.000e-03, eta: 5:07:40, time: 0.061, data_time: 0.000, memory: 576, loss: 0.0007
2023-02-05 22:27:02,204 - mmcls - INFO - Epoch [8][800/1563]	lr: 1.000e-03, eta: 5:07:33, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:27:08,293 - mmcls - INFO - Epoch [8][900/1563]	lr: 1.000e-03, eta: 5:07:25, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:27:14,398 - mmcls - INFO - Epoch [8][1000/1563]	lr: 1.000e-03, eta: 5:07:19, time: 0.061, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:27:20,588 - mmcls - INFO - Epoch [8][1100/1563]	lr: 1.000e-03, eta: 5:07:14, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0012
2023-02-05 22:27:26,786 - mmcls - INFO - Epoch [8][1200/1563]	lr: 1.000e-03, eta: 5:07:10, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0011
2023-02-05 22:27:32,980 - mmcls - INFO - Epoch [8][1300/1563]	lr: 1.000e-03, eta: 5:07:05, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0008
2023-02-05 22:27:39,178 - mmcls - INFO - Epoch [8][1400/1563]	lr: 1.000e-03, eta: 5:07:00, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:27:45,375 - mmcls - INFO - Epoch [8][1500/1563]	lr: 1.000e-03, eta: 5:06:56, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0011
2023-02-05 22:27:49,244 - mmcls - INFO - Saving checkpoint at 8 epochs
2023-02-05 22:27:56,128 - mmcls - INFO - Epoch(val) [8][313]	accuracy_top-1: 94.9100, accuracy_top-5: 99.8300
2023-02-05 22:28:04,541 - mmcls - INFO - Epoch [9][100/1563]	lr: 1.000e-03, eta: 5:06:07, time: 0.084, data_time: 0.020, memory: 576, loss: 0.0004
2023-02-05 22:28:10,720 - mmcls - INFO - Epoch [9][200/1563]	lr: 1.000e-03, eta: 5:06:02, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0007
2023-02-05 22:28:16,912 - mmcls - INFO - Epoch [9][300/1563]	lr: 1.000e-03, eta: 5:05:58, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0007
2023-02-05 22:28:23,095 - mmcls - INFO - Epoch [9][400/1563]	lr: 1.000e-03, eta: 5:05:53, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:28:29,283 - mmcls - INFO - Epoch [9][500/1563]	lr: 1.000e-03, eta: 5:05:48, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:28:35,476 - mmcls - INFO - Epoch [9][600/1563]	lr: 1.000e-03, eta: 5:05:44, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0007
2023-02-05 22:28:41,684 - mmcls - INFO - Epoch [9][700/1563]	lr: 1.000e-03, eta: 5:05:39, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:28:47,881 - mmcls - INFO - Epoch [9][800/1563]	lr: 1.000e-03, eta: 5:05:35, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:28:54,082 - mmcls - INFO - Epoch [9][900/1563]	lr: 1.000e-03, eta: 5:05:30, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0009
2023-02-05 22:29:00,289 - mmcls - INFO - Epoch [9][1000/1563]	lr: 1.000e-03, eta: 5:05:26, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:29:06,491 - mmcls - INFO - Epoch [9][1100/1563]	lr: 1.000e-03, eta: 5:05:22, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0007
2023-02-05 22:29:12,725 - mmcls - INFO - Epoch [9][1200/1563]	lr: 1.000e-03, eta: 5:05:18, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:29:18,944 - mmcls - INFO - Epoch [9][1300/1563]	lr: 1.000e-03, eta: 5:05:14, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0005
2023-02-05 22:29:25,156 - mmcls - INFO - Epoch [9][1400/1563]	lr: 1.000e-03, eta: 5:05:09, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0016
2023-02-05 22:29:31,373 - mmcls - INFO - Epoch [9][1500/1563]	lr: 1.000e-03, eta: 5:05:05, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:29:35,241 - mmcls - INFO - Saving checkpoint at 9 epochs
2023-02-05 22:29:41,961 - mmcls - INFO - Epoch(val) [9][313]	accuracy_top-1: 94.9800, accuracy_top-5: 99.8500
2023-02-05 22:29:50,346 - mmcls - INFO - Epoch [10][100/1563]	lr: 1.000e-03, eta: 5:04:20, time: 0.084, data_time: 0.020, memory: 576, loss: 0.0010
2023-02-05 22:29:56,532 - mmcls - INFO - Epoch [10][200/1563]	lr: 1.000e-03, eta: 5:04:16, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:30:02,722 - mmcls - INFO - Epoch [10][300/1563]	lr: 1.000e-03, eta: 5:04:11, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0005
2023-02-05 22:30:08,916 - mmcls - INFO - Epoch [10][400/1563]	lr: 1.000e-03, eta: 5:04:06, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0005
2023-02-05 22:30:15,126 - mmcls - INFO - Epoch [10][500/1563]	lr: 1.000e-03, eta: 5:04:02, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:30:21,330 - mmcls - INFO - Epoch [10][600/1563]	lr: 1.000e-03, eta: 5:03:58, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0011
2023-02-05 22:30:27,543 - mmcls - INFO - Epoch [10][700/1563]	lr: 1.000e-03, eta: 5:03:53, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:30:33,750 - mmcls - INFO - Epoch [10][800/1563]	lr: 1.000e-03, eta: 5:03:49, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0012
2023-02-05 22:30:39,953 - mmcls - INFO - Epoch [10][900/1563]	lr: 1.000e-03, eta: 5:03:44, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:30:46,163 - mmcls - INFO - Epoch [10][1000/1563]	lr: 1.000e-03, eta: 5:03:40, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0007
2023-02-05 22:30:52,356 - mmcls - INFO - Epoch [10][1100/1563]	lr: 1.000e-03, eta: 5:03:35, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0007
2023-02-05 22:30:58,545 - mmcls - INFO - Epoch [10][1200/1563]	lr: 1.000e-03, eta: 5:03:30, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:31:04,745 - mmcls - INFO - Epoch [10][1300/1563]	lr: 1.000e-03, eta: 5:03:25, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0008
2023-02-05 22:31:10,937 - mmcls - INFO - Epoch [10][1400/1563]	lr: 1.000e-03, eta: 5:03:21, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0011
2023-02-05 22:31:17,128 - mmcls - INFO - Epoch [10][1500/1563]	lr: 1.000e-03, eta: 5:03:16, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0010
2023-02-05 22:31:21,003 - mmcls - INFO - Saving checkpoint at 10 epochs
2023-02-05 22:31:27,804 - mmcls - INFO - Epoch(val) [10][313]	accuracy_top-1: 94.9100, accuracy_top-5: 99.8300
2023-02-05 22:31:36,236 - mmcls - INFO - Epoch [11][100/1563]	lr: 1.000e-03, eta: 5:02:36, time: 0.084, data_time: 0.020, memory: 576, loss: 0.0006
2023-02-05 22:31:42,424 - mmcls - INFO - Epoch [11][200/1563]	lr: 1.000e-03, eta: 5:02:31, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0008
2023-02-05 22:31:48,614 - mmcls - INFO - Epoch [11][300/1563]	lr: 1.000e-03, eta: 5:02:26, time: 0.062, data_time: 0.001, memory: 576, loss: 0.0006
2023-02-05 22:31:54,800 - mmcls - INFO - Epoch [11][400/1563]	lr: 1.000e-03, eta: 5:02:21, time: 0.062, data_time: 0.000, memory: 576, loss: 0.0008
